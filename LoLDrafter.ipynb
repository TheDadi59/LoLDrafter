{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bidGcWoNePY",
        "outputId": "8108b4b2-28b8-4a4d-b666-532755a86c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.3.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: tzdata, pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.4 tzdata-2023.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install -U pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43LutPd056JT",
        "outputId": "124ad9a2-e7e9-46c9-ef91-cdac83afa1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "6rgSYCbsOQUu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montage du Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek3r7LQrYoqv",
        "outputId": "21cf4340-9755-4d8e-9bad-fb51078ace08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "#data_clean = \"/content/drive/MyDrive/LoLDrafter/data/Match_data11 _clean.csv\"\n",
        "data_clean_path = \"/content/drive/MyDrive/LoLDrafter/data/match_data.csv\"\n",
        "\n",
        "columns = ['WIN'] + [f'ID_{k}' for k in range(1, 11)] + [f'ROLE_{k}' for k in range(1, 11)]\n",
        "df = pd.read_csv(data_clean_path, sep=';', names=columns)\n",
        "df = df.replace(' ', pd.NA).dropna(axis=0) # Filter out the rows that contain \" \"\n",
        "df['WIN'] = df['WIN'].astype(int)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dBlMBLkZPTT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "c04fd1dd-eb2c-48b6-d9b2-d28226ea423a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   WIN   ID_1   ID_2   ID_3   ID_4   ID_5   ID_6   ID_7   ID_8   ID_9  ID_10  \\\n",
              "0    1   19.0   64.0  517.0  145.0  117.0  887.0    9.0   91.0   22.0  910.0   \n",
              "1    1   54.0   64.0  134.0   81.0   35.0   55.0    9.0   48.0  498.0  117.0   \n",
              "5    0   57.0    5.0   24.0  526.0   85.0  267.0   51.0   63.0   77.0  126.0   \n",
              "6    1  117.0    2.0  113.0  498.0  112.0  147.0  104.0   32.0  122.0  876.0   \n",
              "7    0   18.0  412.0   78.0  266.0   68.0  122.0   58.0  267.0   80.0  163.0   \n",
              "\n",
              "  ROLE_1   ROLE_2   ROLE_3   ROLE_4    ROLE_5   ROLE_6   ROLE_7   ROLE_8  \\\n",
              "0    TOP   JUNGLE   MIDDLE   BOTTOM   UTILITY      TOP   JUNGLE   MIDDLE   \n",
              "1    TOP   JUNGLE   MIDDLE   BOTTOM   UTILITY   MIDDLE   JUNGLE      TOP   \n",
              "5    TOP   JUNGLE   MIDDLE   BOTTOM   UTILITY      TOP   JUNGLE   MIDDLE   \n",
              "6    TOP   JUNGLE   MIDDLE   BOTTOM   UTILITY      TOP   JUNGLE   MIDDLE   \n",
              "7    TOP   JUNGLE   MIDDLE   BOTTOM   UTILITY      TOP   JUNGLE   MIDDLE   \n",
              "\n",
              "    ROLE_9   ROLE_10  \n",
              "0   BOTTOM   UTILITY  \n",
              "1   BOTTOM   UTILITY  \n",
              "5   BOTTOM   UTILITY  \n",
              "6   BOTTOM   UTILITY  \n",
              "7   BOTTOM   UTILITY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d266b20-38ba-411c-87d8-b3aad66d3b65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WIN</th>\n",
              "      <th>ID_1</th>\n",
              "      <th>ID_2</th>\n",
              "      <th>ID_3</th>\n",
              "      <th>ID_4</th>\n",
              "      <th>ID_5</th>\n",
              "      <th>ID_6</th>\n",
              "      <th>ID_7</th>\n",
              "      <th>ID_8</th>\n",
              "      <th>ID_9</th>\n",
              "      <th>ID_10</th>\n",
              "      <th>ROLE_1</th>\n",
              "      <th>ROLE_2</th>\n",
              "      <th>ROLE_3</th>\n",
              "      <th>ROLE_4</th>\n",
              "      <th>ROLE_5</th>\n",
              "      <th>ROLE_6</th>\n",
              "      <th>ROLE_7</th>\n",
              "      <th>ROLE_8</th>\n",
              "      <th>ROLE_9</th>\n",
              "      <th>ROLE_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>887.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>910.0</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>TOP</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>117.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>412.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "      <td>TOP</td>\n",
              "      <td>JUNGLE</td>\n",
              "      <td>MIDDLE</td>\n",
              "      <td>BOTTOM</td>\n",
              "      <td>UTILITY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d266b20-38ba-411c-87d8-b3aad66d3b65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d266b20-38ba-411c-87d8-b3aad66d3b65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d266b20-38ba-411c-87d8-b3aad66d3b65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0864d744-aa33-422e-982e-ce27e23deab5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0864d744-aa33-422e-982e-ce27e23deab5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0864d744-aa33-422e-982e-ce27e23deab5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_champions = 166\n",
        "\n",
        "# Encode the input champion ids as one-hot for every champion\n",
        "def encode_champion(champion_id):\n",
        "  correspondances = [\n",
        "    266, 103, 84, 166, 12, 32, 34, 1, 523, 22,\n",
        "    136, 268, 432, 200, 53, 63, 201, 233, 51, 164,\n",
        "    69, 31, 42, 122, 131, 119, 36, 245, 60, 28, 81,\n",
        "    9, 114, 105, 3, 41, 86, 150, 79, 104, 887, 120,\n",
        "    74, 910, 420, 39, 427, 40, 59, 24, 126, 202, 222,\n",
        "    145, 429, 43, 30, 38, 55, 10, 141, 85, 121, 203,\n",
        "    240, 96, 897, 7, 64, 89, 876, 127, 236, 117, 99,\n",
        "    54, 90, 57, 11, 902, 21, 62, 82, 25, 950, 267,\n",
        "    75, 111, 518, 76, 895, 56, 20, 2, 61, 516, 80,\n",
        "    78, 555, 246, 133, 497, 33, 421, 526, 888, 58, 107,\n",
        "    92, 68, 13, 360, 113, 235, 147, 875, 35, 98, 102,\n",
        "    27, 14, 15, 72, 37, 16, 50, 517, 134, 223, 163,\n",
        "    91, 44, 17, 412, 18, 48, 23, 4, 29, 77, 6, 110,\n",
        "    67, 45, 161, 711, 254, 234, 112, 8, 106, 19, 498,\n",
        "    101, 5, 157, 777, 83, 350, 154, 238, 221, 115, 26,\n",
        "    142, 143\n",
        "  ]\n",
        "  encoding = np.zeros(nb_champions)\n",
        "  index = correspondances.index(champion_id)\n",
        "  encoding[index] = 1\n",
        "  return encoding\n",
        "\n",
        "def encode_champions(champions_ids):\n",
        "  \"\"\"\n",
        "  Encodes the given list of champions ids into an input vector of size nb_champions * 10 (number of players in each LoL game)\n",
        "  \"\"\"\n",
        "  encoding = np.array([])\n",
        "  for id in champions_ids:\n",
        "    encoding = np.concatenate((encoding, encode_champion(id)))\n",
        "  return encoding\n",
        "\n",
        "def encode_role(role):\n",
        "  roles = {\n",
        "      \"TOP\": 0,\n",
        "      \"JUNGLE\": 1,\n",
        "      \"MIDDLE\": 2,\n",
        "      \"BOTTOM\": 3,\n",
        "      \"UTILITY\": 4\n",
        "  }\n",
        "  role = role.strip()\n",
        "  encoding = np.zeros(len(roles))\n",
        "  encoding[roles[role]] = 1\n",
        "  return encoding\n",
        "\n",
        "def encode_roles(roles):\n",
        "  encoding = np.array([])\n",
        "  for role in roles:\n",
        "    encoding = np.concatenate((encoding, encode_role(role)))\n",
        "  return encoding\n",
        "\n",
        "ids = [266, 76, 895, 56, 20, 2, 61, 516, 80, 78]\n",
        "encode_champions(ids)\n",
        "roles = [\"TOP\",\t\"JUNGLE\",\t\"MIDDLE\",\t\"BOTTOM\",\t\"UTILITY\",\t\"TOP\",\t\"JUNGLE\",\t\"MIDDLE\",\t\"BOTTOM\",\t\"UTILITY\"]\n",
        "encode_roles(roles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNwZX47GT9BL",
        "outputId": "96db7a20-2983-42eb-e633-6bc424988784"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_row(row):\n",
        "  row = [int(champion_id) for champion_id in row[:10]] + [role for role in row[10:]]\n",
        "  version_1 = np.concatenate((encode_champions(row[:10]), encode_roles(row[10:])))\n",
        "  teams_reversed = row[5:10] + row[:5]\n",
        "  roles_reversed = row[15:] + row[10:15]\n",
        "  version_2 = np.concatenate((encode_champions(teams_reversed), encode_roles(roles_reversed)))\n",
        "  return np.array(version_1), np.array(version_2)\n",
        "\n",
        "def augment_data(X, y):\n",
        "  nb_features = 1710\n",
        "  new_X = np.array([augment_row(row) for row in X]).reshape((-1, nb_features))\n",
        "  new_y = np.array([(label, 1-label) for label in y]).flatten()\n",
        "  return new_X, new_y"
      ],
      "metadata": {
        "id": "VBuewZvm_OL4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training, validation and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop([\"WIN\"], axis=1)\n",
        "X = X.values\n",
        "\n",
        "Y = df['WIN']\n",
        "X, Y = augment_data(X, Y)\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "5hZinipXPfE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e10b78-ecec-4333-8d45-ef586d1587d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((122534, 1710), (122534,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_, y_train, y_ = train_test_split(X, Y, test_size=0.15, stratify=Y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_, y_, test_size=0.5, stratify=y_)\n",
        "\n",
        "y_train.shape, y_val.shape, y_test.shape, X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BskkYd10l-Ce",
        "outputId": "879c1fdf-70a2-4edc-d0ff-805536bc39e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((104153,), (9190,), (9191,), (104153, 1710), (9190, 1710), (9191, 1710))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def fit_eval_model(model, X_train, y_train, X_val, y_val,):\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  train_predictions = model.predict(X_train)\n",
        "  train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "  eval_predictions = model.predict(X_val)\n",
        "  eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "  print(\"Training Accuracy:\", train_accuracy)\n",
        "  print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "  print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "  print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))\n",
        "  return train_accuracy, eval_accuracy"
      ],
      "metadata": {
        "id": "YjnBEkj8Dn63"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First model: SVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "lambdas = [1 ** -i for i in range(5)]\n",
        "degrees = list(range(1, 5))\n",
        "\n",
        "train_accuracies, eval_accuracies = [[]] * len(lambdas), [[]] * len(lambdas)\n",
        "\"\"\"\n",
        "for idx_l, _lambda in enumerate(lambdas):\n",
        "  for degree in  tqdm(degrees):\n",
        "    model_svc = SVC(kernel='poly', C=_lambda, degree=degree) # With fewer examples, a linear kernel works best (0.6 val accuracy vs)\n",
        "    model_svc.fit(X_train, y_train)\n",
        "\n",
        "    train_predictions = model_svc.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    train_accuracies[idx_l].append(train_accuracy)\n",
        "\n",
        "    print(\"Training Accuracy:\", train_accuracy)\n",
        "    print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "    eval_predictions = model_svc.predict(X_val)\n",
        "    eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "    eval_accuracies[idx_l].append(eval_accuracy)\n",
        "\n",
        "    print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "    print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))\n",
        "\n",
        "train_accuracies, eval_accuracies\"\"\"\n",
        "svc_model = SVC(kernel='poly')\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = svc_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "eval_predictions = svc_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "R90sDFJrhNbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second model: Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = logistic_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "eval_predictions = logistic_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "-e-s-a1uldc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78c2c36-e690-46f2-b736-5f7ef19844c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.5917782026768642\n",
            "Classification Report (Training):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.57      0.58     21149\n",
            "           1       0.59      0.62      0.60     21737\n",
            "\n",
            "    accuracy                           0.59     42886\n",
            "   macro avg       0.59      0.59      0.59     42886\n",
            "weighted avg       0.59      0.59      0.59     42886\n",
            "\n",
            "Evaluation Accuracy: 0.5337323177366703\n",
            "Classification Report (Evaluation):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.51      0.52      5439\n",
            "           1       0.54      0.56      0.55      5589\n",
            "\n",
            "    accuracy                           0.53     11028\n",
            "   macro avg       0.53      0.53      0.53     11028\n",
            "weighted avg       0.53      0.53      0.53     11028\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third model: Decision trees\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = tree_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "eval_predictions = tree_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "JnzpeQXTsDl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64963d1f-f033-4b61-8b88-67e9d31169bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Classification Report (Training):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     21149\n",
            "           1       1.00      1.00      1.00     21737\n",
            "\n",
            "    accuracy                           1.00     42886\n",
            "   macro avg       1.00      1.00      1.00     42886\n",
            "weighted avg       1.00      1.00      1.00     42886\n",
            "\n",
            "Evaluation Accuracy: 0.5858723249909322\n",
            "Classification Report (Evaluation):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.58      0.58      5439\n",
            "           1       0.59      0.60      0.59      5589\n",
            "\n",
            "    accuracy                           0.59     11028\n",
            "   macro avg       0.59      0.59      0.59     11028\n",
            "weighted avg       0.59      0.59      0.59     11028\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fourth model: Random forests\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_model = RandomForestClassifier()\n",
        "forest_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = forest_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "eval_predictions = forest_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "Xvi1vdXvsbrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a4660d-e3ec-4e89-ba72-b6d4eba2139a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Classification Report (Training):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     52076\n",
            "           1       1.00      1.00      1.00     52077\n",
            "\n",
            "    accuracy                           1.00    104153\n",
            "   macro avg       1.00      1.00      1.00    104153\n",
            "weighted avg       1.00      1.00      1.00    104153\n",
            "\n",
            "Evaluation Accuracy: 0.6078346028291621\n",
            "Classification Report (Evaluation):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.63      0.62      4595\n",
            "           1       0.61      0.59      0.60      4595\n",
            "\n",
            "    accuracy                           0.61      9190\n",
            "   macro avg       0.61      0.61      0.61      9190\n",
            "weighted avg       0.61      0.61      0.61      9190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fifth model: XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = xgb_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "eval_predictions = xgb_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "h-QeWpy3sojh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afae305c-6b06-4108-f585-dd9d04c91728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.6496758849041645\n",
            "Classification Report (Training):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.59      0.63     21149\n",
            "           1       0.64      0.71      0.67     21737\n",
            "\n",
            "    accuracy                           0.65     42886\n",
            "   macro avg       0.65      0.65      0.65     42886\n",
            "weighted avg       0.65      0.65      0.65     42886\n",
            "\n",
            "Evaluation Accuracy: 0.5428001450852376\n",
            "Classification Report (Evaluation):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.49      0.51      5439\n",
            "           1       0.54      0.60      0.57      5589\n",
            "\n",
            "    accuracy                           0.54     11028\n",
            "   macro avg       0.54      0.54      0.54     11028\n",
            "weighted avg       0.54      0.54      0.54     11028\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sixth model: Naive Bayes\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = nb_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "eval_predictions = nb_model.predict(X_val)\n",
        "eval_accuracy = accuracy_score(y_val, eval_predictions)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Classification Report (Training):\\n\", classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"Evaluation Accuracy:\", eval_accuracy)\n",
        "print(\"Classification Report (Evaluation):\\n\", classification_report(y_val, eval_predictions))"
      ],
      "metadata": {
        "id": "ETplmlsYtFFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd388471-d2e7-49d4-8c2a-885dd47246f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.5853658536585366\n",
            "Classification Report (Training):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.59      0.58     21149\n",
            "           1       0.59      0.58      0.59     21737\n",
            "\n",
            "    accuracy                           0.59     42886\n",
            "   macro avg       0.59      0.59      0.59     42886\n",
            "weighted avg       0.59      0.59      0.59     42886\n",
            "\n",
            "Evaluation Accuracy: 0.5349111352919841\n",
            "Classification Report (Evaluation):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.54      0.53      5439\n",
            "           1       0.54      0.53      0.54      5589\n",
            "\n",
            "    accuracy                           0.53     11028\n",
            "   macro avg       0.53      0.53      0.53     11028\n",
            "weighted avg       0.54      0.53      0.53     11028\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seventh model: MLP\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "nb_champions = 166\n",
        "nb_roles = 5\n",
        "nb_players = 10\n",
        "input_dim = (nb_champions + nb_roles) * nb_players\n",
        "\n",
        "# A simple Multi-Layer Perceptron model with four layers: input layer with 64 ReLU units, and two hidden layers with ReLU units (32 and 16 respectively).\n",
        "# Output layer uses a sigmoid activation function since we're doing binary classification\n",
        "mlp_model = Sequential([\n",
        "    Dense(units=64, activation='relu', input_dim=input_dim),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=16, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "X_train, X_val = np.array(X_train), np.array(X_val)\n",
        "history = mlp_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "KMMAB6vUtWm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a9f269-cf81-4fda-fe74-d004f0b65e58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3255/3255 [==============================] - 17s 4ms/step - loss: 0.6908 - accuracy: 0.5247 - val_loss: 0.6885 - val_accuracy: 0.5311\n",
            "Epoch 2/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.6791 - accuracy: 0.5620 - val_loss: 0.6875 - val_accuracy: 0.5508\n",
            "Epoch 3/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.6442 - accuracy: 0.6131 - val_loss: 0.7048 - val_accuracy: 0.5428\n",
            "Epoch 4/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.5812 - accuracy: 0.6740 - val_loss: 0.7565 - val_accuracy: 0.5561\n",
            "Epoch 5/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.5132 - accuracy: 0.7290 - val_loss: 0.8224 - val_accuracy: 0.5624\n",
            "Epoch 6/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.4586 - accuracy: 0.7649 - val_loss: 0.9129 - val_accuracy: 0.5653\n",
            "Epoch 7/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.4151 - accuracy: 0.7905 - val_loss: 0.9996 - val_accuracy: 0.5717\n",
            "Epoch 8/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.3812 - accuracy: 0.8114 - val_loss: 1.1581 - val_accuracy: 0.5677\n",
            "Epoch 9/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.3532 - accuracy: 0.8264 - val_loss: 1.3269 - val_accuracy: 0.5720\n",
            "Epoch 10/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.3299 - accuracy: 0.8405 - val_loss: 1.4572 - val_accuracy: 0.5662\n",
            "Epoch 11/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.3122 - accuracy: 0.8498 - val_loss: 1.5089 - val_accuracy: 0.5745\n",
            "Epoch 12/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.2940 - accuracy: 0.8605 - val_loss: 1.6444 - val_accuracy: 0.5663\n",
            "Epoch 13/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.2776 - accuracy: 0.8683 - val_loss: 1.7506 - val_accuracy: 0.5726\n",
            "Epoch 14/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.2658 - accuracy: 0.8743 - val_loss: 1.8879 - val_accuracy: 0.5707\n",
            "Epoch 15/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.2520 - accuracy: 0.8820 - val_loss: 2.0406 - val_accuracy: 0.5745\n",
            "Epoch 16/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.2420 - accuracy: 0.8871 - val_loss: 2.1410 - val_accuracy: 0.5745\n",
            "Epoch 17/50\n",
            "3255/3255 [==============================] - 15s 5ms/step - loss: 0.2316 - accuracy: 0.8930 - val_loss: 2.1829 - val_accuracy: 0.5773\n",
            "Epoch 18/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.2223 - accuracy: 0.8976 - val_loss: 2.2833 - val_accuracy: 0.5834\n",
            "Epoch 19/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.2137 - accuracy: 0.9020 - val_loss: 2.4771 - val_accuracy: 0.5844\n",
            "Epoch 20/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.2059 - accuracy: 0.9063 - val_loss: 2.5061 - val_accuracy: 0.5814\n",
            "Epoch 21/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.2003 - accuracy: 0.9102 - val_loss: 2.6130 - val_accuracy: 0.5840\n",
            "Epoch 22/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1922 - accuracy: 0.9132 - val_loss: 2.7698 - val_accuracy: 0.5902\n",
            "Epoch 23/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1865 - accuracy: 0.9169 - val_loss: 2.8363 - val_accuracy: 0.5893\n",
            "Epoch 24/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1791 - accuracy: 0.9212 - val_loss: 2.9143 - val_accuracy: 0.5934\n",
            "Epoch 25/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1742 - accuracy: 0.9224 - val_loss: 3.0369 - val_accuracy: 0.5923\n",
            "Epoch 26/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1701 - accuracy: 0.9244 - val_loss: 3.1467 - val_accuracy: 0.5913\n",
            "Epoch 27/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1645 - accuracy: 0.9280 - val_loss: 3.2332 - val_accuracy: 0.5894\n",
            "Epoch 28/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1592 - accuracy: 0.9304 - val_loss: 3.3944 - val_accuracy: 0.5908\n",
            "Epoch 29/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1553 - accuracy: 0.9324 - val_loss: 3.4106 - val_accuracy: 0.5896\n",
            "Epoch 30/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1509 - accuracy: 0.9354 - val_loss: 3.5964 - val_accuracy: 0.5874\n",
            "Epoch 31/50\n",
            "3255/3255 [==============================] - 15s 5ms/step - loss: 0.1472 - accuracy: 0.9364 - val_loss: 3.6070 - val_accuracy: 0.5906\n",
            "Epoch 32/50\n",
            "3255/3255 [==============================] - 15s 5ms/step - loss: 0.1443 - accuracy: 0.9384 - val_loss: 3.6186 - val_accuracy: 0.5879\n",
            "Epoch 33/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1396 - accuracy: 0.9405 - val_loss: 3.8196 - val_accuracy: 0.5925\n",
            "Epoch 34/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1340 - accuracy: 0.9436 - val_loss: 3.9502 - val_accuracy: 0.5917\n",
            "Epoch 35/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1341 - accuracy: 0.9437 - val_loss: 3.9676 - val_accuracy: 0.5909\n",
            "Epoch 36/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1296 - accuracy: 0.9460 - val_loss: 3.9508 - val_accuracy: 0.5904\n",
            "Epoch 37/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1241 - accuracy: 0.9480 - val_loss: 4.0591 - val_accuracy: 0.5891\n",
            "Epoch 38/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1241 - accuracy: 0.9488 - val_loss: 4.2127 - val_accuracy: 0.5898\n",
            "Epoch 39/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1185 - accuracy: 0.9509 - val_loss: 4.4406 - val_accuracy: 0.5878\n",
            "Epoch 40/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1152 - accuracy: 0.9528 - val_loss: 4.4159 - val_accuracy: 0.5906\n",
            "Epoch 41/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1141 - accuracy: 0.9528 - val_loss: 4.5274 - val_accuracy: 0.5892\n",
            "Epoch 42/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1115 - accuracy: 0.9545 - val_loss: 4.5444 - val_accuracy: 0.5905\n",
            "Epoch 43/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1082 - accuracy: 0.9548 - val_loss: 4.6661 - val_accuracy: 0.5905\n",
            "Epoch 44/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.1073 - accuracy: 0.9568 - val_loss: 4.8073 - val_accuracy: 0.5886\n",
            "Epoch 45/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1046 - accuracy: 0.9579 - val_loss: 4.7759 - val_accuracy: 0.5936\n",
            "Epoch 46/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1012 - accuracy: 0.9595 - val_loss: 4.8193 - val_accuracy: 0.5934\n",
            "Epoch 47/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.1002 - accuracy: 0.9593 - val_loss: 4.8233 - val_accuracy: 0.5961\n",
            "Epoch 48/50\n",
            "3255/3255 [==============================] - 13s 4ms/step - loss: 0.0964 - accuracy: 0.9608 - val_loss: 5.1388 - val_accuracy: 0.5936\n",
            "Epoch 49/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.0947 - accuracy: 0.9614 - val_loss: 5.1455 - val_accuracy: 0.5923\n",
            "Epoch 50/50\n",
            "3255/3255 [==============================] - 14s 4ms/step - loss: 0.0955 - accuracy: 0.9618 - val_loss: 5.2660 - val_accuracy: 0.5927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.save('mlp-model.keras')\n",
        "\n",
        "loss_mlp, accuracy_mlp = mlp_model.evaluate(X_test, y_test)\n",
        "loss_mlp, accuracy_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3rZabKrcf0Z",
        "outputId": "761b4e7e-bb6e-4138-8b48-e8f38b235ea7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 1s 2ms/step - loss: 5.1663 - accuracy: 0.5981\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.166328430175781, 0.5980851054191589)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eighth model: RNN using LSTM units\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "nb_champions = 166\n",
        "nb_roles = 5\n",
        "nb_players = 10\n",
        "input_dim = (nb_champions + nb_roles) * nb_players\n",
        "\n",
        "embedding_dim=256\n",
        "X_train_rnn, X_val_rnn, X_test_rnn = X_train.reshape((X_train.shape[0], 1, input_dim)), X_val.reshape((X_val.shape[0], 1, input_dim)), X_test.reshape((X_test.shape[0], 1, input_dim))\n",
        "y_train_rnn, y_val_rnn, y_test_rnn = y_train.reshape((-1, 1)), y_val.reshape((-1, 1)), y_test.reshape((-1, 1))\n",
        "print(X_train_rnn.shape)\n",
        "print(X_train_rnn)\n",
        "\n",
        "rnn_model = Sequential([\n",
        "    LSTM(units=40, input_shape=(1, input_dim), return_sequences=True),\n",
        "    LSTM(units=20, return_sequences=True),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "rnn_history = rnn_model.fit(X_train_rnn, y_train_rnn, epochs=50, batch_size=32, validation_data=(X_val_rnn, y_val_rnn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6U3iJfs27vJ",
        "outputId": "c4c16c91-180d-4c51-ce1f-48a9d9f0e166"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(104153, 1, 1710)\n",
            "[[[0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 1.]]]\n",
            "Epoch 1/50\n",
            "3255/3255 [==============================] - 29s 7ms/step - loss: 0.6906 - accuracy: 0.5250 - val_loss: 0.6889 - val_accuracy: 0.5329\n",
            "Epoch 2/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.6821 - accuracy: 0.5551 - val_loss: 0.6902 - val_accuracy: 0.5326\n",
            "Epoch 3/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.6702 - accuracy: 0.5743 - val_loss: 0.6962 - val_accuracy: 0.5349\n",
            "Epoch 4/50\n",
            "3255/3255 [==============================] - 35s 11ms/step - loss: 0.6389 - accuracy: 0.6184 - val_loss: 0.7265 - val_accuracy: 0.5428\n",
            "Epoch 5/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.5658 - accuracy: 0.6889 - val_loss: 0.7904 - val_accuracy: 0.5569\n",
            "Epoch 6/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.4762 - accuracy: 0.7556 - val_loss: 0.9001 - val_accuracy: 0.5598\n",
            "Epoch 7/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.4072 - accuracy: 0.7994 - val_loss: 1.0517 - val_accuracy: 0.5668\n",
            "Epoch 8/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.3538 - accuracy: 0.8292 - val_loss: 1.2531 - val_accuracy: 0.5659\n",
            "Epoch 9/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.3160 - accuracy: 0.8504 - val_loss: 1.4288 - val_accuracy: 0.5740\n",
            "Epoch 10/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.2838 - accuracy: 0.8655 - val_loss: 1.5982 - val_accuracy: 0.5719\n",
            "Epoch 11/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.2590 - accuracy: 0.8791 - val_loss: 1.7480 - val_accuracy: 0.5767\n",
            "Epoch 12/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.2359 - accuracy: 0.8900 - val_loss: 1.9053 - val_accuracy: 0.5797\n",
            "Epoch 13/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.2173 - accuracy: 0.8997 - val_loss: 2.1020 - val_accuracy: 0.5819\n",
            "Epoch 14/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.2012 - accuracy: 0.9078 - val_loss: 2.2580 - val_accuracy: 0.5815\n",
            "Epoch 15/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.1865 - accuracy: 0.9147 - val_loss: 2.3481 - val_accuracy: 0.5855\n",
            "Epoch 16/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1741 - accuracy: 0.9205 - val_loss: 2.4653 - val_accuracy: 0.5848\n",
            "Epoch 17/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.1611 - accuracy: 0.9263 - val_loss: 2.6596 - val_accuracy: 0.5843\n",
            "Epoch 18/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1517 - accuracy: 0.9299 - val_loss: 2.7848 - val_accuracy: 0.5837\n",
            "Epoch 19/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.1434 - accuracy: 0.9347 - val_loss: 2.8232 - val_accuracy: 0.5860\n",
            "Epoch 20/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1327 - accuracy: 0.9395 - val_loss: 2.9211 - val_accuracy: 0.5900\n",
            "Epoch 21/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1277 - accuracy: 0.9417 - val_loss: 3.0283 - val_accuracy: 0.5914\n",
            "Epoch 22/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1207 - accuracy: 0.9441 - val_loss: 3.0852 - val_accuracy: 0.5887\n",
            "Epoch 23/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.1137 - accuracy: 0.9478 - val_loss: 3.1105 - val_accuracy: 0.5909\n",
            "Epoch 24/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.1073 - accuracy: 0.9509 - val_loss: 3.2114 - val_accuracy: 0.5935\n",
            "Epoch 25/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.1022 - accuracy: 0.9533 - val_loss: 3.2774 - val_accuracy: 0.5942\n",
            "Epoch 26/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.0953 - accuracy: 0.9561 - val_loss: 3.4064 - val_accuracy: 0.5923\n",
            "Epoch 27/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0921 - accuracy: 0.9577 - val_loss: 3.4397 - val_accuracy: 0.5968\n",
            "Epoch 28/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.0886 - accuracy: 0.9597 - val_loss: 3.4571 - val_accuracy: 0.5958\n",
            "Epoch 29/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0818 - accuracy: 0.9625 - val_loss: 3.5480 - val_accuracy: 0.5985\n",
            "Epoch 30/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.0779 - accuracy: 0.9645 - val_loss: 3.5889 - val_accuracy: 0.5963\n",
            "Epoch 31/50\n",
            "3255/3255 [==============================] - 26s 8ms/step - loss: 0.0730 - accuracy: 0.9663 - val_loss: 3.6442 - val_accuracy: 0.5941\n",
            "Epoch 32/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0712 - accuracy: 0.9677 - val_loss: 3.7184 - val_accuracy: 0.5913\n",
            "Epoch 33/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0669 - accuracy: 0.9693 - val_loss: 3.7364 - val_accuracy: 0.5936\n",
            "Epoch 34/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.0646 - accuracy: 0.9703 - val_loss: 3.7791 - val_accuracy: 0.5915\n",
            "Epoch 35/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.0632 - accuracy: 0.9714 - val_loss: 3.7860 - val_accuracy: 0.5998\n",
            "Epoch 36/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0587 - accuracy: 0.9731 - val_loss: 3.8780 - val_accuracy: 0.5923\n",
            "Epoch 37/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0552 - accuracy: 0.9750 - val_loss: 3.8970 - val_accuracy: 0.5966\n",
            "Epoch 38/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0560 - accuracy: 0.9749 - val_loss: 3.8282 - val_accuracy: 0.5946\n",
            "Epoch 39/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0520 - accuracy: 0.9762 - val_loss: 3.8856 - val_accuracy: 0.5979\n",
            "Epoch 40/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.0494 - accuracy: 0.9778 - val_loss: 3.9401 - val_accuracy: 0.5997\n",
            "Epoch 41/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.0469 - accuracy: 0.9788 - val_loss: 3.9874 - val_accuracy: 0.5985\n",
            "Epoch 42/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0448 - accuracy: 0.9800 - val_loss: 4.0827 - val_accuracy: 0.5962\n",
            "Epoch 43/50\n",
            "3255/3255 [==============================] - 24s 7ms/step - loss: 0.0440 - accuracy: 0.9806 - val_loss: 4.0641 - val_accuracy: 0.5986\n",
            "Epoch 44/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0409 - accuracy: 0.9818 - val_loss: 4.1038 - val_accuracy: 0.5993\n",
            "Epoch 45/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0415 - accuracy: 0.9823 - val_loss: 4.0934 - val_accuracy: 0.5960\n",
            "Epoch 46/50\n",
            "3255/3255 [==============================] - 21s 7ms/step - loss: 0.0404 - accuracy: 0.9827 - val_loss: 4.0642 - val_accuracy: 0.5978\n",
            "Epoch 47/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0362 - accuracy: 0.9841 - val_loss: 4.1181 - val_accuracy: 0.5972\n",
            "Epoch 48/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.0373 - accuracy: 0.9842 - val_loss: 4.1157 - val_accuracy: 0.6009\n",
            "Epoch 49/50\n",
            "3255/3255 [==============================] - 22s 7ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 4.1219 - val_accuracy: 0.5987\n",
            "Epoch 50/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.0330 - accuracy: 0.9862 - val_loss: 4.2023 - val_accuracy: 0.5995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.save('rnn-model.keras')\n",
        "\n",
        "loss_rnn, accuracy_rnn = rnn_model.evaluate(X_test_rnn, y_test_rnn)\n",
        "loss_rnn, accuracy_rnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cSLWcmnwJ3t",
        "outputId": "cb27bc95-6492-4e61-f5f3-a69ec48dc1fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 1s 4ms/step - loss: 4.1240 - accuracy: 0.5973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.124024391174316, 0.597323477268219)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ninth model: RNNs using LSTM layers with Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "\n",
        "nb_champions = 166\n",
        "nb_roles = 5\n",
        "nb_players = 10\n",
        "input_dim = (nb_champions + nb_roles) * nb_players\n",
        "\n",
        "X_train_rnn, X_val_rnn, X_test_rnn = X_train.reshape((X_train.shape[0], 1, input_dim)), X_val.reshape((X_val.shape[0], 1, input_dim)), X_test.reshape((X_test.shape[0], 1, input_dim))\n",
        "y_train_rnn, y_val_rnn, y_test_rnn = y_train.reshape((-1, 1)), y_val.reshape((-1, 1)), y_test.reshape((-1, 1))\n",
        "\n",
        "# A second RNN model using LSTM layers with dropout to see if it reduces variance\n",
        "rnn_model2 = Sequential([\n",
        "    LSTM(units=40, input_shape=(1, input_dim),return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=20, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "rnn_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "rnn_history2 = rnn_model2.fit(X_train_rnn, y_train_rnn, epochs=50, batch_size=32, validation_data=(X_val_rnn, y_val_rnn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GtQ96ZBzUyb",
        "outputId": "eb450e67-afe7-44a1-b117-32ac2a704f54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3255/3255 [==============================] - 21s 6ms/step - loss: 0.6906 - accuracy: 0.5253 - val_loss: 0.6889 - val_accuracy: 0.5320\n",
            "Epoch 2/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.6830 - accuracy: 0.5531 - val_loss: 0.6893 - val_accuracy: 0.5317\n",
            "Epoch 3/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.6750 - accuracy: 0.5691 - val_loss: 0.6900 - val_accuracy: 0.5405\n",
            "Epoch 4/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.6575 - accuracy: 0.5975 - val_loss: 0.6995 - val_accuracy: 0.5493\n",
            "Epoch 5/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.6170 - accuracy: 0.6469 - val_loss: 0.7254 - val_accuracy: 0.5569\n",
            "Epoch 6/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.5632 - accuracy: 0.6935 - val_loss: 0.7584 - val_accuracy: 0.5588\n",
            "Epoch 7/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.5128 - accuracy: 0.7316 - val_loss: 0.8125 - val_accuracy: 0.5688\n",
            "Epoch 8/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.4773 - accuracy: 0.7557 - val_loss: 0.8448 - val_accuracy: 0.5693\n",
            "Epoch 9/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.4502 - accuracy: 0.7725 - val_loss: 0.8961 - val_accuracy: 0.5755\n",
            "Epoch 10/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.9587 - val_accuracy: 0.5786\n",
            "Epoch 11/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.4119 - accuracy: 0.7975 - val_loss: 1.0121 - val_accuracy: 0.5790\n",
            "Epoch 12/50\n",
            "3255/3255 [==============================] - 23s 7ms/step - loss: 0.3960 - accuracy: 0.8056 - val_loss: 1.0319 - val_accuracy: 0.5806\n",
            "Epoch 13/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.3827 - accuracy: 0.8144 - val_loss: 1.1143 - val_accuracy: 0.5828\n",
            "Epoch 14/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.3713 - accuracy: 0.8215 - val_loss: 1.0909 - val_accuracy: 0.5849\n",
            "Epoch 15/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.3642 - accuracy: 0.8249 - val_loss: 1.1316 - val_accuracy: 0.5815\n",
            "Epoch 16/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.3535 - accuracy: 0.8306 - val_loss: 1.1363 - val_accuracy: 0.5844\n",
            "Epoch 17/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.3451 - accuracy: 0.8353 - val_loss: 1.2047 - val_accuracy: 0.5859\n",
            "Epoch 18/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.3363 - accuracy: 0.8411 - val_loss: 1.1921 - val_accuracy: 0.5842\n",
            "Epoch 19/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.3304 - accuracy: 0.8440 - val_loss: 1.2179 - val_accuracy: 0.5866\n",
            "Epoch 20/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.3226 - accuracy: 0.8482 - val_loss: 1.2527 - val_accuracy: 0.5865\n",
            "Epoch 21/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.3162 - accuracy: 0.8521 - val_loss: 1.2502 - val_accuracy: 0.5864\n",
            "Epoch 22/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.3083 - accuracy: 0.8572 - val_loss: 1.2723 - val_accuracy: 0.5886\n",
            "Epoch 23/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.3045 - accuracy: 0.8583 - val_loss: 1.2788 - val_accuracy: 0.5898\n",
            "Epoch 24/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.2987 - accuracy: 0.8610 - val_loss: 1.2703 - val_accuracy: 0.5881\n",
            "Epoch 25/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.2916 - accuracy: 0.8654 - val_loss: 1.3199 - val_accuracy: 0.5880\n",
            "Epoch 26/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2857 - accuracy: 0.8692 - val_loss: 1.3509 - val_accuracy: 0.5875\n",
            "Epoch 27/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2843 - accuracy: 0.8687 - val_loss: 1.3200 - val_accuracy: 0.5884\n",
            "Epoch 28/50\n",
            "3255/3255 [==============================] - 18s 6ms/step - loss: 0.2788 - accuracy: 0.8729 - val_loss: 1.3567 - val_accuracy: 0.5890\n",
            "Epoch 29/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2725 - accuracy: 0.8773 - val_loss: 1.3666 - val_accuracy: 0.5875\n",
            "Epoch 30/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2687 - accuracy: 0.8777 - val_loss: 1.3760 - val_accuracy: 0.5884\n",
            "Epoch 31/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2671 - accuracy: 0.8786 - val_loss: 1.3794 - val_accuracy: 0.5853\n",
            "Epoch 32/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2626 - accuracy: 0.8823 - val_loss: 1.3839 - val_accuracy: 0.5934\n",
            "Epoch 33/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2584 - accuracy: 0.8827 - val_loss: 1.4228 - val_accuracy: 0.5924\n",
            "Epoch 34/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2544 - accuracy: 0.8851 - val_loss: 1.3842 - val_accuracy: 0.5918\n",
            "Epoch 35/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2524 - accuracy: 0.8877 - val_loss: 1.4389 - val_accuracy: 0.5917\n",
            "Epoch 36/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2495 - accuracy: 0.8887 - val_loss: 1.4536 - val_accuracy: 0.5918\n",
            "Epoch 37/50\n",
            "3255/3255 [==============================] - 19s 6ms/step - loss: 0.2467 - accuracy: 0.8903 - val_loss: 1.4375 - val_accuracy: 0.5915\n",
            "Epoch 38/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2411 - accuracy: 0.8931 - val_loss: 1.4292 - val_accuracy: 0.5916\n",
            "Epoch 39/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2389 - accuracy: 0.8948 - val_loss: 1.4332 - val_accuracy: 0.5912\n",
            "Epoch 40/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2364 - accuracy: 0.8965 - val_loss: 1.4510 - val_accuracy: 0.5899\n",
            "Epoch 41/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2319 - accuracy: 0.8986 - val_loss: 1.4418 - val_accuracy: 0.5918\n",
            "Epoch 42/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.2288 - accuracy: 0.8987 - val_loss: 1.4622 - val_accuracy: 0.5926\n",
            "Epoch 43/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2264 - accuracy: 0.9003 - val_loss: 1.4532 - val_accuracy: 0.5874\n",
            "Epoch 44/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2205 - accuracy: 0.9034 - val_loss: 1.4944 - val_accuracy: 0.5879\n",
            "Epoch 45/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.2209 - accuracy: 0.9033 - val_loss: 1.4832 - val_accuracy: 0.5908\n",
            "Epoch 46/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2170 - accuracy: 0.9063 - val_loss: 1.5165 - val_accuracy: 0.5939\n",
            "Epoch 47/50\n",
            "3255/3255 [==============================] - 17s 5ms/step - loss: 0.2168 - accuracy: 0.9056 - val_loss: 1.4875 - val_accuracy: 0.5948\n",
            "Epoch 48/50\n",
            "3255/3255 [==============================] - 20s 6ms/step - loss: 0.2133 - accuracy: 0.9074 - val_loss: 1.5296 - val_accuracy: 0.5906\n",
            "Epoch 49/50\n",
            "3255/3255 [==============================] - 16s 5ms/step - loss: 0.2097 - accuracy: 0.9097 - val_loss: 1.5088 - val_accuracy: 0.5913\n",
            "Epoch 50/50\n",
            "3255/3255 [==============================] - 18s 5ms/step - loss: 0.2077 - accuracy: 0.9093 - val_loss: 1.5257 - val_accuracy: 0.5903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model2.save('rnn-model2.keras')\n",
        "\n",
        "loss2, acc2 = rnn_model2.evaluate(X_test_rnn, y_test_rnn)\n",
        "loss2, acc2\n",
        "x = np.array()\n",
        "rnn_model2.predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR8dD9bCBgZK",
        "outputId": "619e1881-4311-45a5-945a-537c6fc61eb0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 1s 3ms/step - loss: 1.5260 - accuracy: 0.5984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5260289907455444, 0.598411500453949)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_predictions(X_data):\n",
        "    roles = [\"TOP\",\t\"JUNGLE\",\t\"MIDDLE\",\t\"BOTTOM\",\t\"UTILITY\",\t\"TOP\",\t\"JUNGLE\",\t\"MIDDLE\",\t\"BOTTOM\",\t\"UTILITY\"]\n",
        "    champion_encoding = encode_champions(X_data)\n",
        "    roles_encoding = encode_roles(roles)\n",
        "\n",
        "    # Concatenate the two encodings along the second axis (axis=1)\n",
        "    X = np.concatenate((champion_encoding, roles_encoding)).reshape((1, -1))\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = mlp_model.predict(X)\n",
        "    threshold=0.5\n",
        "    # If your output layer uses sigmoid activation for binary classification, you might want to threshold the predictions\n",
        "    binary_predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "    return binary_predictions\n",
        "\n",
        "# Example usage:\n",
        "predictions = make_predictions()\n",
        "print(predictions)\n",
        "\n",
        "predictions2 = make_predictions()\n",
        "print(predictions2)"
      ],
      "metadata": {
        "id": "gxSNYcPYc-0F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}